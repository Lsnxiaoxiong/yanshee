## **Yanshee 机器人课程详细大纲（共 32 课时，每课时 45 分钟）**


### **一、[技术导论与环境搭建](./lesson/01_dev_env.md)（2 课时）**
> 目标：了解机器人系统架构与开发环境搭建

1. **课程介绍与机器人入门（0.5）**
   - Yanshee 机器人硬件结构介绍（传感器、摄像头、麦克风、关节等）
   - 实际演示：用手机 App 控制机器人动作
   - 本节目标：理解机器人主要硬件组成并能用手机 App 进行基本控制验证
2. **软件与开发环境安装（1.5）**
   - 手机端控制 App 安装与配对 
   - Python 环境安装（Windows/Mac）
   - VSCode IDE 安装与插件配置
   - pytorch+cuda+cuDNN 安装
   - 文件传输工具（FileZilla / WinSCP / FinalShell）使用
   - SSH 连接到机器人并运行简单命令
   - 本节目标：完成开发环境安装并能通过 SSH 成功连接机器人

------

### **二、Python 编程基础（2 课时）**

> 目标：让零基础学生能写出简单的控制逻辑脚本

1. **Python 基础语法（0.5）**
   - 输出 `print()` 与注释
   - 数据类型：整型、浮点型、布尔值、字符串
   - 容器类型：列表、字典、元组
   - 类型转换与基本运算符
   - 本节目标：掌握 Python 基本语法，能编写简单脚本打印与处理变量
2. **流程控制（0.5）**
   - `if` 条件判断
   - `for` / `while` 循环
   - 嵌套循环与 `break` / `continue`
   - 本节目标：能用条件与循环解决基本逻辑问题（计数、筛选、循环任务）
3. **函数与模块（0.5）**
   - 函数定义与调用
   - 传入参数与返回值
   - Python 内置模块导入
   - 第三方模块安装与使用（`pip`）
   - 本节目标：编写可重用函数并能使用 pip 安装第三方包
4. **类与面向对象基础（0.5）**
   - 类的定义与实例化
   - 属性与方法
   - 本节目标：用类封装简单对象（如机器人关节或传感器接口）

------

### **三、OpenCV 图像处理（2 课时）**

> 目标：理解计算机视觉基本操作

1. **图像读写与显示（0.5）**
   - `cv2.imread()`、`cv2.imshow()`、`cv2.imwrite()`
   - 图片颜色通道（BGR、灰度）
   - 图像尺寸调整与裁剪
   - 本节目标：能读取/显示/保存图像并做基础颜色/尺寸转换
2. **视频流处理（0.5）**
   - 调用摄像头实时捕捉视频
   - 保存视频文件
   - 帧处理（灰度化、模糊、边缘检测）
   - 本节目标：搭建摄像头读取流水线并保存或处理帧数据
3. **人脸检测基础（1）**
   - Haar 特征检测
   - DNN 人脸检测（预训练模型）
   - 检测结果可视化
   - 本节目标：使用 Haar 或 DNN 模型完成基本人脸检测并可视化结果

------

### **四、机器人控制（6 课时）**

> 目标：用 Python API 控制机器人运动、获取传感器数据、处理语音与图像

1. **API 总览与运动控制（2）**
   - YanAPI 简介与安装
   - 机器人姿态控制：关节角度、运动轨迹
   - 行走与转向
   - 机器人平衡与摔倒检测
   - 本节目标：安装并调用 YanAPI，完成关节/姿态控制示例
2. **图像与传感器数据获取（2）**
   - 调用摄像头 API
   - 获取传感器（距离、触碰）数据
   - 环境光与音量检测
   - 本节目标：读取并记录摄像头与常用传感器数据，能在程序中使用这些数据
3. **语音与语音识别（2）**
   - 语音播放（TTS）
   - 本节目标：实现 TTS 播放与基础语音识别流程，能用语音触发简单动作

------

### **五、人工智能（AI）模块（10 课时）**

> 目标：让学生理解并实践 AI 在机器人上的应用

1. **YOLO 目标检测（3）**
   - 数据标注（LabelImg 工具）
   - 模型训练流程（基于 YOLOv5/YOLOv8）
   - 模型测试与精度评估
   - 模型部署到机器人
   - 本节目标：完成一个最小可运行的目标检测训练—标注、训练、推理并部署到机器人
2. **大语言模型（3）**
   - LLM 基本原理与应用场景
   - 云端 API 调用（DeepSeek、Qwen、科大讯飞、文心一言等）
   - 本地部署 LLM、VLM（可选）
   - 本节目标：理解 LLM 调用流程并实现至少一种云端 API 调用示例
3. **多模态与 MCP（4）**
   - MCP（Model Context Protocol）介绍
   - MCP 客户端与服务端搭建
   - 开源项目实践：index-tts、sherpa-onnx
   - 本节目标：搭建简单 MCP 客户端/服务端并完成一次多模态模型调用示例

------

### **六、大模型与机器人整合（4 课时）**

> 目标：将 AI 模型与机器人感知/控制结合

1. **系统整合思路（1）**
   - 摄像头 → AI 模型 → 控制逻辑 → 机器人动作
   - 网络通信与数据传输方式
   - 本节目标：绘制并解释端到端系统架构与数据流程
2. **示例项目：手势识别 + 无接触控制（3）**
   - 手势识别模型部署
   - 根据手势执行不同动作
   - 实现“无接触交互”功能
   - 本节目标：部署手势识别并实现至少三个手势到动作的映射与演示

------

### **七、动手实践（4 课时）**

> 目标：学生独立完成一个综合项目

1. **项目选题与分组（0.5）**
    - 本节目标：确定项目题目并完成小组分配与角色定义

2. **功能拆解与任务分配（0.5）**
    - 本节目标：将项目拆解为可交付的任务并制定时间表

3. **项目开发与调试（2）**

    - 本节目标：完成项目核心功能的开发与调试，并准备演示材料
   



### 八、答辩展示（2课时）
 - 本节目标：向全班演示项目成果，提交代码仓库、部署说明与演示视频，接受答辩评分

